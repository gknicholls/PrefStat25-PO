note$true.rho=0.925            #if syth then this is true rho
#note$true.beta=0             #if NA then simulated (and ordered) - set to zero to remove beta
note$sNF=2                   #number of features in synth data (K in notes)
note$SYNTHTYPE='priorstate' #'poststate' #
#'poststate' means truth is last state in old file,
#'priorstate' means tau, beta and U are sampled using priors rest are true.p etc
# oldsynth means it uses synthetic data from a past run
note$TRUEINPUTFILE="./example-FT-dir/example-FT.RData" #if poststate
note$OLDSYNTHINPUTFILE="./testFUN-dir/testFUN.RData" #if oldsynth
#model setup
note$NF=NA                    #number of features in U, Z so U is NB x NF x T - at least MA/2 gives all possible PO's - set to NA to get floor(MA/2)
note$constrainbeta=FALSE     #if TRUE then beta is contrained to be decreasing
note$model='lkddown'           #'bidir', 'lkddown' or 'lkdup' or 'lkdnat' or 'prior' or 'lkmallow' at the moment - 'prior' gives the joint prior of beta,theta,rho,U
note$PhPar=list(model=note$model,
rfac=c(shape1=1,shape2=1/6,ncp=1), #prior parameters for rho
p=list(a=1,b=9),      #prior parameters for p(queue jumping), q(bidir), p(mallows)
q=list(a=1,b=1),      #p is beta prior parameters c(1,9) is default in most runs - called "subjective"
p.m=list(a=0,b=10))   #p.m is p mallows - uniform(a,b) for mallows penalty param
#MCMC drivers
note$RANDSEED=101
note$NEWRUN=TRUE             #set to FALSE if resarting old run
note$DRAW=FALSE
note$savefile='example-FT.RData'  #write MCMC samples to savefile
note$loadfile=NA             #if restarting set this to old savefile
note$LOADDIR=NA              #if restarting set this to old savedir
note$MCMC.SWEEPS=10000
note$SUBSAMPLE.INTERVAL=10   #get note$MCMC.SWEEPS/note$SUBSAMPLE.INTERVAL samples
note$DOWRITE=TRUE            #set to false if you dont want to save along the way - sensible for short runs only.
note$WRITE.SUBSAMPLE=100     #write the state to a file less frequently as this takes time for long runs
note$Usweeps=c(0,2)          #number of U-sweeps in doU (all b's per proposal) and doU2 (one b at a time) for each beta-sweep
note$UALLFRACUPD=c(0,1)      #fraction of two (fast,slow) U-updates to use
note$rho.reps=5              #number of rho-updates per sweep
note$theta.reps=5            #number of theta-updates per sweep
note$rhotheta.reps=5
note$rhotheta.wrap.reps=1
note$rhothetaU.wrap.reps=3
note$p.reps=5
note$q.reps=5
note$comment="Fixed time example (or short time anyway) for review"
#if the update is switched off (debugging etc) make sure init value set to something sensible
note$STARTSTATE='disordered'    #'disordered','ordered','oldstart', 'true' - 'true' only possible if synth data
note$STARTFILE="filename.RData"            #if oldstart, give the filename containing the run here - run will start from final state
note$init.beta.fac=1         #if synth & true start this multiplies init beta
note$init.U.fac=1            #if synth & true start this multiplies init U - set close to zero if testing U mcmc
#init beta is all 0 and init tau is prior sample
note$init.p=ifelse(note$STARTSTATE=='disordered',0.95,0.05)             #0.05 plausible
note$init.q=ifelse(note$STARTSTATE=='disordered',0.5,0.05)              #0.05 plausible
note$init.theta=ifelse(note$STARTSTATE=='disordered',0,0.95)          #init theta - 0.95 plausible
note$init.rho=ifelse(note$STARTSTATE=='disordered',0.1,0.9)             #init rho - 0.9 plausible
note$DOTHETA=FALSE            #do we switch on the theta-update
note$DOBETA=FALSE             #do we switch on the beta-update
note$DORHO=TRUE              #do we switch on the rho-update
note$DORHOTHETA=FALSE         #combined rho-theta update
note$DOU=TRUE                #do we switch on the U-update
note$DOP=TRUE                #P-update
note$DOQ=(note$model=='bidir')                #Q-update
note$DOTAU=FALSE              #tau-update
#parallel drivers - dont use this - it seems more efficient to use the cores to do multiple independent scalar runs.
#Also in current version it isnt actually any faster - seems to depend delicately on where functions defined.
#was working now v. slow
note$DOPAR=FALSE             #use parallel proc?
if (note$DOPAR) library(parallel)
note$nthread=2               #number of parallel threads - as a rule of thumb, seems not much gain above 4
#note$optimise.par.blocks=FALSE
note$split.years=1118 #c(1119,1134,1137)
#######################################################
# where are we working?
setwd(note$RUNDIR)
#old work functions including alot of legacy stuff need to be in RUNDIR
source(file="dating.R")
source(file="makedatafun.R")
source(file="makesynthdatafun.R")
source(file="makeparametersfun.R")
source(file="pofun.R")
#Functions simulating priors and evalutaing log-prior densities
source(file="modelfun.R")
#Functions for output analysis
source(file="outputfun.R")
#Functions related to the MCMC
source(file="mcmcfun.R",verbose=note$VERBOSE)
#main mcmc function
source(file='mcmcPO.R')
if (note$NEWRUN) {
temp.dir=paste('./',sub('.RData','',note$savefile),'-dir',sep='')
count=1; while (dir.exists(temp.dir)) {temp.dir=paste('./',sub('.RData','',note$savefile),'-',letters[count],'-dir',sep=''); count=count+1}
note$SAVEDIR=temp.dir
dir.create(note$SAVEDIR)
} else {
note$SAVEDIR=note$LOADDIR
}
if (note$NEWRUN) {
this.file <- parent.frame(2)$ofile;
file.copy(this.file, paste(note$SAVEDIR,'/',sub('.RData','',note$savefile),'-main.R',sep=''))
}
#if (FALSE) {
#run MCMC - for longer runs this wont complete so O will never be returned, output via file saving
O=mcmcPO(note)
#save the output if it wasnt already saved
if (!note$DOWRITE) my.save(paste(note$SAVEDIR,'/',note$savefile,sep=''),O)
output=outputanalysis(out.dir=note$SAVEDIR,out.file=note$savefile,burn=10,
yoi=(note$B:note$E)-note$B+1,
pdf.file=NA,P.samples=NA,full.analysis=TRUE)
if (note$DOPAR) {stopCluster(cl); gc()}
#}
gpars<-par()
i=match(c("cin","cra","csi","cxy","din","page"),names(gpars))
gpars<-gpars[-i]
library(MASS)
library(mnem)       # needed for transitive.reduction/closure
library(igraph)
library(Rgraphviz)
library(graph)
library(coda)       # for MCMC output analysis
#library(lecount)    # count linear extensions of a PO
library(partitions) # used by dimension functions
#update this to suit yourself
wd<-"C:/Users/nicholls.NICHOLLS2389/OneDrive - Nexus365/Documents/GitHub/PrefStat25-PO/Code for Practical - Without lecount/"
setwd(wd)
source(file="pofun.R")
source(file="pofun_aux.R")
source(file="modelfun.R")
source(file="dimfun.R")
nle
set.seed(10);
M=8
h<-rZPO(M)   # for now this is just a random PO
#h[i,j]=1 if i>j
h
sum(h)
choose(M,2)-sum(h)
showDAG(h,edge.color='black',vertex.color=NA,vertex.size=25,edge.arrow.size=0.5)
showDAG(h,edge.color='black',vertex.color=NA,vertex.size=25,edge.arrow.size=0.5)
title('transitive closure of h')
# find the list of top nodes - no "in" edges
(top=which(apply(h,2,sum)==0))
# list the bottom nodes - no "out" edges
(bot=which(apply(h,1,sum)==0))
dagdepth(h)
h.empty=0*h
h.total=h.empty; h.total[upper.tri(h.total)]<-1
par(mfrow=c(1,2))
showDAG(h.empty,vertex.color=NA,vertex.size=25)
title('Empty order')
showDAG(h.total,edge.color='black',vertex.color=NA,vertex.size=15,edge.arrow.size=0.5)
title('Complete order')
showDAG(h.total,edge.color='black',vertex.color=NA,vertex.size=15,edge.arrow.size=0.25)
title('Complete order')
par(gpars)
gpars<-par()
i=match(c("cin","cra","csi","cxy","din","page"),names(gpars))
gpars<-gpars[-i]
gpars<-par()
i=match(c("cin","cra","csi","cxy","din","page"),names(gpars))
gpars<-gpars[-i]
library(MASS)
library(mnem)       # needed for transitive.reduction/closure
library(igraph)
library(Rgraphviz)
library(graph)
library(coda)       # for MCMC output analysis
#library(lecount)    # count linear extensions of a PO
library(partitions) # used by dimension functions
#update this to suit yourself
wd<-"C:/Users/nicholls.NICHOLLS2389/OneDrive - Nexus365/Documents/GitHub/PrefStat25-PO/Code for Practical - Without lecount/"
setwd(wd)
source(file="pofun.R")
source(file="pofun_aux.R")
source(file="modelfun.R")
source(file="dimfun.R")
set.seed(10);
M=8
h<-rZPO(M)   # for now this is just a random PO
#h[i,j]=1 if i>j
h
sum(h)
choose(M,2)-sum(h)
showDAG(h,edge.color='black',vertex.color=NA,vertex.size=25,edge.arrow.size=0.5)
title('transitive closure of h')
# find the list of top nodes - no "in" edges
(top=which(apply(h,2,sum)==0))
# list the bottom nodes - no "out" edges
(bot=which(apply(h,1,sum)==0))
dagdepth(h)
h.empty=0*h
h.total=h.empty; h.total[upper.tri(h.total)]<-1
par(mfrow=c(1,2))
showDAG(h.empty,vertex.color=NA,vertex.size=25)
title('Empty order')
showDAG(h.total,edge.color='black',vertex.color=NA,vertex.size=15,edge.arrow.size=0.25)
title('Complete order')
par(gpars)
dagdepth(h.empty) #depth is the length of longest chain, counting vertices in chain
dagdepth(h.total); dagdepth(h.total)==M
hr<-transitive.reduction(h)
showDAG(hr,edge.color='black',vertex.color=NA,vertex.size=25,edge.arrow.size=0.5)
title('transitive reduction of h')
vcols=rep(NA,M);
vcols[top]<-'lightgreen'; vcols[bot]<-'pink'
# igraph orders the edges by first vertex
i=which(t(h)==1)
j=which(t(h)!=t(hr))
j.in.i=match(j,i)
ecols=rep('black',length(i))
ecols[j.in.i]<-'lightblue'
showDAG(h,vertex.color=vcols,edge.color=ecols,vertex.size=25,
edge.arrow.size=0.5)
legend('topright',cex=0.9,lty=c(1,1,NA,NA),pch=c(NA,NA,16,16),col=c('black','lightblue','lightgreen','pink'),lwd=c(2,2,NA,NA),
legend=c('reduction','closure','max set','min set'),bty="n")
v=matrix(c(1,2,3,1,3,2),3,2)
v
hi<-intersect.TO(v)
hi
showDAG(hi,edge.color='black',vertex.color=NA,vertex.size=35,edge.arrow.size=0.5)
par(mfrow=c(1,2))
M=4
b<-matrix(c(0,1,0,0,0,0,0,0,0,1,0,1,0,0,0,0),M,M,byrow=TRUE)
row.names(b)<-colnames(b)<-1:M
showDAG(b,edge.color='black',vertex.color=NA,vertex.size=45,edge.arrow.size=0.5)
title('example partial order')
(le<-le.expand(b));
dim(le)[2];
nle(b);
bc<-intersect.TO(le)
# poset bc should be the same as b
showDAG(bc,edge.color='black',vertex.color=NA,vertex.size=45,edge.arrow.size=0.5)
title('intersection of its LEs')
par(gpars)
le
(b.realiser<-decompose(b))
all(intersect.TO(b.realiser)==b) # intersect LEs in realiser gives back PO
dimension(b)
cpo=crown.PO(6)
showDAG(cpo,edge.color='black',vertex.color=NA,vertex.size=45,edge.arrow.size=0.5)
le<-le.expand(cpo)
le
(cpo.realiser<-decompose(cpo))     # takes a couple of seconds
all(intersect.TO(cpo.realiser)==cpo)
M=5
h=matrix(c(0,1,1,1,1,0,0,1,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0),M,M,byrow=TRUE)
colnames(h)<-rownames(h)<-1:M
showDAG(transitive.reduction(h),edge.color='black',vertex.color=NA,vertex.size=25,edge.arrow.size=0.5)
(le=le.expand(h))
q=le[,1] # start state must be a LE
T=10000  # simulate T steps
X<-matrix(NA,M,T) # store the state of the queue
for (t in 1:T) {
i=sample(1:(M-1),1)         # propose to swap q[i] and q[i+1]
if (h[q[i],q[i+1]]!=1) {    # if q[i+1] isnt below q[i] in the PO
q[c(i,i+1)]=q[c(i+1,i)]   # swap q[i] and q[i+1]
}
X[,t]=q                     # save the current queue state
}
ord=apply(X,2,function(x){
which(apply(le,2,function(y){all(x==y)}))
})
(ft<-table(ord)/T)
le.str<-apply(le,2,function(x){paste(x,collapse = ' ')})
barplot(ft~le.str,las=2,cex.names=0.5,
ylab='probability',xlab='',
main='distribution of random orders - noise free case',
cex.main=0.8,cex.axis=0.7);
abline(h=1/nle(h),col=2,lwd=2,lty=2)
set.seed(10)
M=8
h.true<-rZPO(M)       # make a random PO with n items
showDAG(transitive.reduction(h.true),edge.color='black',
vertex.color=NA,vertex.size=35,edge.arrow.size=0.5)
title("true PO")
N=10                 # try experimenting with smaller N
Y<-matrix(NA,M,N)
for (i in 1:N) {
Y[,i]<-PunifLE(h.true)
}
Y
h.hat<-intersect.TO(Y)
par(mfrow=c(1,2))
showDAG(transitive.reduction(h.hat),edge.color='black',
vertex.color=NA,vertex.size=35,edge.arrow.size=0.5)
title("MLE PO")
showDAG(transitive.reduction(h.true),edge.color='black',
vertex.color=NA,vertex.size=35,edge.arrow.size=0.5)
title("true PO")
nle(h.true)
decompose(h.true) # smallest number of lists that identify the PO
N=3                 # try experimenting with smaller N
Y<-matrix(NA,M,N)
for (i in 1:N) {
Y[,i]<-PunifLE(h.true)
}
Y
h.hat<-intersect.TO(Y)
par(mfrow=c(1,2))
showDAG(transitive.reduction(h.hat),edge.color='black',
vertex.color=NA,vertex.size=35,edge.arrow.size=0.5)
title("MLE PO")
showDAG(transitive.reduction(h.true),edge.color='black',
vertex.color=NA,vertex.size=35,edge.arrow.size=0.5)
N=2                 # try experimenting with smaller N
Y<-matrix(NA,M,N)
for (i in 1:N) {
Y[,i]<-PunifLE(h.true)
}
Y
h.hat<-intersect.TO(Y)
par(mfrow=c(1,2))
showDAG(transitive.reduction(h.hat),edge.color='black',
vertex.color=NA,vertex.size=35,edge.arrow.size=0.5)
title("MLE PO")
showDAG(transitive.reduction(h.true),edge.color='black',
vertex.color=NA,vertex.size=35,edge.arrow.size=0.5)
title("true PO")
set.seed(11)
N=10
size=sample(2:M,N,replace=TRUE)
S<-lapply(size,function(x){sample(1:M,x,replace=FALSE)})
h.true.sub<-lapply(S,function(x){suborder(h.true,x)})
showDAGs(B=1,T=N,PO=h.true.sub)
par(gpars)
Y<-vector('list',N)
for (i in 1:N) {
Y[[i]]<-PunifLE(h.true.sub[[i]])
}
Y
h.est<-intersect.SO(Y)
par(mfrow=c(1,2));
showDAG(transitive.reduction(h.true),edge.color='black',
vertex.color=NA,vertex.size=35,edge.arrow.size=0.5)
title("true PO")
showDAG(transitive.reduction(h.est),edge.color='black',
vertex.color=NA,vertex.size=35,edge.arrow.size=0.5)
title("estimated PO")
mv<-seq(8,16,2);   # if no lecount()
#mv<-seq(35,47,2); # if lecount() loaded - unwise to try above 50 (memory)
mvl=length(mv); rt<-numeric(mvl)
pb<-txtProgressBar(min=1, max=mvl, style=3)
for (i in 1:mvl) {
h<-crown.PO(mv[i])
rt[i]<-system.time({nle(h)})[3] # how long to calculate # LEs?
setTxtProgressBar(pb, i)
flush.console()
}
# The runtime measured for m=8 may be zero - ignore warning
par(gpars)
plot(mv,rt,log='y',type='l',ylab='run time',xlab='number of items');
points(mv,rt,pch=4)
set.seed(1)
M<-20
#  N=number of samples, S=subsample step, T=number of steps
N=100
S=M^2
T=N*S
POu<-rupo(M,N,S,T,DRAW=TRUE)
s=10; step=floor(N/s);
showDAGs(B=1,T=N,poi=seq(step,N,step),PO=POu)
Du=sapply(POu,dagdepth)
effectiveSize(Du) # if interested in MCMC mixing and convergence
par(gpars); plot(Du,type='l',ylab='Depth of random PO',xlab='MCMC step',
main='evolving depth of PO sampled U.A.R.')
hist(Du,breaks=seq(0.5,M+0.5,1),xlab='PO depth',
main='Depth dbn, uniform PO prior',freq=FALSE)
table(Du)/length(Du)
set.seed(6)
M=6 # number of items/nodes in PO
K=3 # number of features (columns of U/Z)
(rho=rRprior())  # the correlation within of rows of U
Sig=matrix(rho,K,K); diag(Sig)=1; # correlation matrix
U=mvrnorm(M,rep(0,K),Sig) # the feature matrix U, one row for each item
vp<-latent2order(U) # convert each column k+1:K to a total order, ranking by U[,k]
mu<-order2partial(vp,M); # intersect the column orders
muc<-my.transitive.closure(mu) # take the transitive closure
mur<-transitive.reduction(mu)  # and transitive reduction
par(mfrow=c(2,2),mai=c(0,0,0,0))
plot(0,0,xlim=c(1,K+1),ylim=c(-4,4),type='n',axes=FALSE,ann=FALSE)
cl=0; apply(U,1,function(x){lines(x,lwd=2,col=(cl<<-cl+1))})
title(expression('U'),line=-3)
legend('topright',legend=1:n,lty=1,col=1:n,lwd=2)
showDAG(mur,vertex.color=NA,vertex.size=25)
par(mfrow=c(2,2),mai=c(0,0,0,0))
plot(0,0,xlim=c(1,K+1),ylim=c(-4,4),type='n',axes=FALSE,ann=FALSE)
cl=0; apply(U,1,function(x){lines(x,lwd=2,col=(cl<<-cl+1))})
title(expression('U'),line=-3)
legend('topright',legend=1:M,lty=1,col=1:n,lwd=2)
par(mfrow=c(2,2),mai=c(0,0,0,0))
plot(0,0,xlim=c(1,K+1),ylim=c(-4,4),type='n',axes=FALSE,ann=FALSE)
cl=0; apply(U,1,function(x){lines(x,lwd=2,col=(cl<<-cl+1))})
title(expression('U'),line=-3)
legend('topright',legend=1:M,lty=1,col=1:M,lwd=2)
showDAG(mur,vertex.color=NA,vertex.size=25)
title(expression('h(U)'),line=-6)
alpha=rnorm(M)
Z=U+alpha # features with covariate additive effect offset
vp<-latent2order(Z)
mz<-order2partial(vp,M);
mzc<-my.transitive.closure(mz)
mzr<-transitive.reduction(mz)
plot(0,0,xlim=c(1,K+1),ylim=c(-4,4),type='n',axes=FALSE,ann=FALSE)
cl=0; apply(Z,1,function(x){lines(x,lwd=2,col=(cl<<-cl+1))})
title(expression(paste("Z=U+X",beta)),line=-3)
showDAG(mzr,vertex.color=NA,vertex.size=25)
title(expression('h(Z)'),line=-6)
par(gpars)
title(expression('h(Z)'),line=-8)
plot(0,0,xlim=c(1,K+1),ylim=c(-4,4),type='n',axes=FALSE,ann=FALSE)
cl=0; apply(Z,1,function(x){lines(x,lwd=2,col=(cl<<-cl+1))})
title(expression(paste("Z=U+X",beta)),line=-3)
showDAG(mzr,vertex.color=NA,vertex.size=25)
title(expression('h(Z)'),line=-8)
alpha=rnorm(M)
Z=U+alpha # features with covariate additive effect offset
vp<-latent2order(Z)
(rho=rRprior())  # the correlation within of rows of U
Sig=matrix(rho,K,K); diag(Sig)=1; # correlation matrix
U=mvrnorm(M,rep(0,K),Sig) # the feature matrix U, one row for each item
vp<-latent2order(U) # convert each column k+1:K to a total order, ranking by U[,k]
mu<-order2partial(vp,M); # intersect the column orders
muc<-my.transitive.closure(mu) # take the transitive closure
mur<-transitive.reduction(mu)  # and transitive reduction
par(mfrow=c(2,2),mai=c(0,0,0,0))
plot(0,0,xlim=c(1,K+1),ylim=c(-4,4),type='n',axes=FALSE,ann=FALSE)
cl=0; apply(U,1,function(x){lines(x,lwd=2,col=(cl<<-cl+1))})
title(expression('U'),line=-3)
legend('topright',legend=1:M,lty=1,col=1:M,lwd=2)
showDAG(mur,vertex.color=NA,vertex.size=25)
title(expression('h(U)'),line=-6)
alpha=rnorm(M)
Z=U+alpha # features with covariate additive effect offset
vp<-latent2order(Z)
mz<-order2partial(vp,M);
mzc<-my.transitive.closure(mz)
mzr<-transitive.reduction(mz)
plot(0,0,xlim=c(1,K+1),ylim=c(-4,4),type='n',axes=FALSE,ann=FALSE)
cl=0; apply(Z,1,function(x){lines(x,lwd=2,col=(cl<<-cl+1))})
title(expression(paste("Z=U+X",beta)),line=-3)
showDAG(mzr,vertex.color=NA,vertex.size=25)
title(expression('h(Z)'),line=-8)
par(gpars)
set.seed(6)
M=6 # number of items/nodes in PO
K=3 # number of features (columns of U/Z)
(rho=rRprior())  # the correlation within of rows of U
Sig=matrix(rho,K,K); diag(Sig)=1; # correlation matrix
U=mvrnorm(M,rep(0,K),Sig) # the feature matrix U, one row for each item
vp<-latent2order(U) # convert each column k+1:K to a total order, ranking by U[,k]
mu<-order2partial(vp,M); # intersect the column orders
muc<-my.transitive.closure(mu) # take the transitive closure
mur<-transitive.reduction(mu)  # and transitive reduction
par(mfrow=c(2,2),mai=c(0,0,0,0))
plot(0,0,xlim=c(1,K+1),ylim=c(-4,4),type='n',axes=FALSE,ann=FALSE)
cl=0; apply(U,1,function(x){lines(x,lwd=2,col=(cl<<-cl+1))})
title(expression('U'),line=-3)
legend('topright',legend=1:M,lty=1,col=1:M,lwd=2)
showDAG(mur,vertex.color=NA,vertex.size=25)
title(expression('h(U)'),line=-6)
alpha=rnorm(M)
Z=U+alpha # features with covariate additive effect offset
vp<-latent2order(Z)
mz<-order2partial(vp,M);
mzc<-my.transitive.closure(mz)
mzr<-transitive.reduction(mz)
plot(0,0,xlim=c(1,K+1),ylim=c(-4,4),type='n',axes=FALSE,ann=FALSE)
cl=0; apply(Z,1,function(x){lines(x,lwd=2,col=(cl<<-cl+1))})
title(expression(paste("Z=U+X",beta)),line=-3)
showDAG(mzr,vertex.color=NA,vertex.size=25)
title(expression('h(Z)'),line=-8)
title(expression('h(Z)'),line=-12)
title(expression('h(Z)'),line=-10)
par(gpars)
M=20
K=10
N=1000
POl<-vector('list',N)
pb<-txtProgressBar(min=0, max=N, style=3)
for (t in 1:N) {
beta=rnorm(M)
POl[[t]]<-my.transitive.closure(rZPO(M,K,b=beta))
setTxtProgressBar(pb, t/N); flush.console()
}
Dl=sapply(POl,dagdepth)
hist(Dl,breaks=seq(0.5,M+0.5,1),xlab='PO depth',
main='Depth dbn, latent feature PO prior',freq=FALSE)
table(Dl)/length(Dl)
plot(density(Du,bw=0.5,from=1,to=M),xlim=c(0,M+1),
main='prior depth dbns',xlab='depth')
lines(density(Dl,bw=0.5,from=1,to=M),col=2)
abline(v=c(1,M),col=3)
legend('topright',legend=c('Uniform','Latent'),col=c(1,2),lty=c(1,1),lwd=2)
M=4
h<-matrix(c(0,1,0,0,0,0,0,0,0,1,0,1,0,0,0,0),M,M,byrow=TRUE)
row.names(h)<-colnames(h)<-1:M
showDAG(h,edge.color='black',
vertex.color=NA,vertex.size=35,edge.arrow.size=0.5)
T=10000;
X=matrix(NA,M,T)
p.val=0.5 # the probability the next item in the list is chosen randomly
for (t in 1:T) {
X[,t]=PunifLE(h,p=p.val)
}
perm=t(enum.seq(1:M))
perm.str=apply(perm,2,function(x){paste(x,collapse = ' ')})
le=le.expand(h)
is.le=1+apply(perm,2,function(x){any(apply(le,2,function(y){all(x==y)}))})
cols=c('lightgrey','lightblue')[is.le]
ord=apply(X,2,function(x){
which(apply(perm,2,function(y){all(x==y)}))
})
ft=table(ord)/T
barplot(ft~perm.str,las=2,cex.names=0.7,col=cols,
ylab='probability',xlab='permutation',
main=paste('distribution of random orders with noise probability = ',p.val),
cex.main=0.8)
legend('topright',legend=c('LE of h','not LE'),
col=c('lightblue','lightgrey'),pch=c(15,15))
